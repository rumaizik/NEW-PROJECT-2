NLP Topic Modeling & Search Engine (TF-IDF + LDA)

A modular Natural Language Processing project that performs topic modeling using TF-IDF vectorization + Latent Dirichlet Allocation (LDA) and provides a simple search interface over documents.

This project is designed with clean code structure, separation of concerns, and production-style organization, suitable for learning, evaluation, and extension.

Features

ğŸ“„ Load and preprocess text documents

ğŸ§¹ Clean text (lowercasing, punctuation removal, normalization)

ğŸ”¢ Convert text into TF-IDF documentâ€“term matrix

ğŸ§  Discover latent topics using LDA

ğŸ” Search documents using cosine similarity

ğŸ§© Modular, extensible codebase (easy to add new models)

Project Structure

NEW-PROJECT-2/
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ documents.txt          # Input text corpus (one document per line)
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ preprocessing.py       # Text cleaning & document loading
â”‚   â”œâ”€â”€ vectorizer.py           # TF-IDF vectorization
â”‚   â”œâ”€â”€ topic_model.py          # LDA topic modeling
â”‚   â””â”€â”€ search_engine.py        # Search over documents
â”‚
â”œâ”€â”€ main.py                     # Entry point
â”œâ”€â”€ requirements.txt            # Dependencies
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md

Installation
1ï¸âƒ£ Clone the repository
git clone https://github.com/rumaizik/NEW-PROJECT-2.git
cd NEW-PROJECT-2
2ï¸âƒ£ Install dependencies
pip install -r requirements.txt

â–¶ï¸ How to Run
python main.py

Output:

Discovered topics with top keywords

Interactive prompt to enter a search query

Ranked documents based on relevance

Input Format

The file data/documents.txt should contain:

One document per line.
Each line is treated as a separate document.


Example:

Machine learning is transforming artificial intelligence.
Natural language processing helps computers understand text.
Topic modeling discovers hidden patterns in documents.

Topic Modeling (LDA)

Vectorization: TF-IDF

Topic Model: Latent Dirichlet Allocation

Configurable number of topics

Reproducible results using fixed random state

Example output:

=== TOPICS DISCOVERED ===
Topic 1: ['models', 'search', 'vector', 'space', 'engines']
Topic 2: ['hidden', 'discovers', 'transforming', 'intelligence']
Topic 3: ['science', 'data', 'learning', 'used', 'widely']

 Search Engine

Uses vector similarity over TF-IDF space

Returns most relevant documents for a query

Designed to mimic basic information retrieval systems

Enter search query: machine learning

ğŸ§©Design Philosophy

Modular: Each component has a single responsibility

Extensible: Easy to swap TF-IDF, LDA, or add embeddings

Readable: Clear function names and structure

Educational + Practical: Suitable for learning and demos

ğŸš€ Possible Extensions

Replace TF-IDF with Word2Vec / Sentence Transformers

Add Streamlit UI

Support larger datasets

Add topic coherence metrics

Persist trained models

ğŸ‘¨â€ğŸ’» Author

Rumaiz Ibrahim K
M.Tech (Industrial Mathematics & Scientific Computing), IIT Madras


ğŸ“œ License

This project is for educational and academic use.